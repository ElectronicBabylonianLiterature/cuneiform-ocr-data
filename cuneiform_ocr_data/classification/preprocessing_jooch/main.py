import pandas as pd
from pathlib import Path
import shutil

from cuneiform_ocr_data.classification.utils import build_ebl_dict

cooh = [
    "GIR3",
    "GAN2",
    "NA",
    "EGIR",
    "KU7",
    "IGv2",
    "EL",
    "IA2",
    "MU",
    "GAN",
    "ASZ3",
    "LIv2",
    "HI",
    "TU",
    "AZ",
    "GU2",
    "AN",
    "SZA3",
    "EREN",
    "UM",
    "BI",
    "SIG",
    "SZA",
    "DA",
    "SUHUR",
    "GA",
    "A2",
    "LAL",
    "DI",
    "LIv1",
    "SZU2",
    "BA",
    "ZI",
    "AB",
    "ESZ",
    "HASZHUR",
    "TUR",
    "NAR",
    "LU2",
    "LAL3",
    "PAB",
    "ME",
    "EME",
    "GI",
    "SIG5",
    "NE",
    "GUL",
    "LAM",
    "LA",
    "IM",
    "TUM",
    "TUG2",
    "GIM",
    "KA2",
    "MUSZ3",
    "AR",
    "KI",
    "DISZ",
    "KAR",
    "UD",
    "SAG",
    "USSU",
    "U2",
    "DAG",
    "AL",
    "MASZhalf",
    "ZA",
    "MESZ",
    "URUDU",
    "AH",
    "KAL",
    "SU",
    "UL",
    "MUN",
    "BAL",
    "BAD",
    "DIR",
    "DUGUD",
    "LIMMU",
    "KA",
    "GISZ",
    "EN",
    "SIK2",
    "HAR",
    "GAD",
    "MASZ",
    "UR",
    "KIN",
    "IL",
    "SILA3",
    "UG",
    "KID",
    "MA",
    "KUGv2",
    "AG",
    "ENGUR",
    "LISZ",
    "GIG",
    "MAH",
    "RA",
    "PI",
    "UZU",
    "TAR",
    "IB",
    "KUR",
    "GAG",
    "IR",
    "DU",
    "MAR",
    "PA",
    "HAL",
    "DIM",
    "SZE",
    "EZEN4",
    "DAM",
    "HA",
    "MI",
    "USZ",
    "ERIM",
    "ILIMMU",
    "RU",
    "SZID",
    "MUNUS",
    "LUM",
    "U",
    "AD",
    "LAGAB",
    "ASZ",
    "RI",
    "IN",
    "IMIN",
    "UR2",
    "LUH",
    "ZU",
    "EZEN",
    "KUGv1",
    "UB",
    "TA",
    "ESZ5",
    "NIG2",
    "DAH",
    "NU",
    "UGU",
    "TAB",
    "ISZTAR",
    "DUG",
    "BU",
    "KAM",
    "NAM",
    "GESZTIN",
    "U3",
    "MIN",
    "HU",
    "URU",
    "KU",
    "NIN",
    "GU4",
    "LUGAL",
    "NI",
    "E2",
    "BALAG",
    "AZUG",
    "MAN",
    "KAB",
    "ZI2",
    "AM",
    "NA4",
    "IA",
    "SZUL",
    "SAR",
    "DUB",
    "LU",
    "TE",
    "GAL",
    "SUR",
    "TAG",
    "ZAG",
    "DUR",
    "IGI",
    "GAB",
    "ISZ",
    "A",
    "SZU",
    "UN",
    "SISKUR",
    "TI",
    "E",
    "I",
]
parsed = [
    "gir₃",
    "gan₂",
    "na",
    "egir",
    "ku₇",
    "igv₂",
    "el",
    "ia₂",
    "mu",
    "gan",
    "aš₃",
    "liv₂",
    "hi",
    "tu",
    "az",
    "gu₂",
    "an",
    "ša₃",
    "eren",
    "um",
    "bi",
    "sig",
    "ša",
    "da",
    "suhur",
    "ga",
    "a₂",
    "lal",
    "di",
    "liv₁",
    "šu₂",
    "ba",
    "zi",
    "ab",
    "eš",
    "hašhur",
    "tur",
    "nar",
    "lu₂",
    "lal₃",
    "pab",
    "me",
    "eme",
    "gi",
    "sig₅",
    "ne",
    "gul",
    "lam",
    "la",
    "im",
    "tum",
    "tug₂",
    "gim",
    "ka₂",
    "muš₃",
    "ar",
    "ki",
    "diš",
    "kar",
    "ud",
    "sag",
    "ussu",
    "u₂",
    "dag",
    "al",
    "mašhalf",
    "za",
    "meš",
    "urudu",
    "ah",
    "kal",
    "su",
    "ul",
    "mun",
    "bal",
    "bad",
    "dir",
    "dugud",
    "limmu",
    "ka",
    "giš",
    "en",
    "sik₂",
    "har",
    "gad",
    "maš",
    "ur",
    "kin",
    "il",
    "sila₃",
    "ug",
    "kid",
    "ma",
    "kugv₂",
    "ag",
    "engur",
    "liš",
    "gig",
    "mah",
    "ra",
    "pi",
    "uzu",
    "tar",
    "ib",
    "kur",
    "gag",
    "ir",
    "du",
    "mar",
    "pa",
    "hal",
    "dim",
    "še",
    "ezen₄",
    "dam",
    "ha",
    "mi",
    "uš",
    "erim",
    "ilimmu",
    "ru",
    "šid",
    "munus",
    "lum",
    "u",
    "ad",
    "lagab",
    "aš",
    "ri",
    "in",
    "imin",
    "ur₂",
    "luh",
    "zu",
    "ezen",
    "kugv₁",
    "ub",
    "ta",
    "eš₅",
    "nig₂",
    "dah",
    "nu",
    "ugu",
    "tab",
    "ištar",
    "dug",
    "bu",
    "kam",
    "nam",
    "geštin",
    "u₃",
    "min",
    "hu",
    "uru",
    "ku",
    "nin",
    "gu₄",
    "lugal",
    "ni",
    "e₂",
    "balag",
    "azug",
    "man",
    "kab",
    "zi₂",
    "am",
    "na₄",
    "ia",
    "šul",
    "sar",
    "dub",
    "lu",
    "te",
    "gal",
    "sur",
    "tag",
    "zag",
    "dur",
    "igi",
    "gab",
    "iš",
    "a",
    "šu",
    "un",
    "siskur",
    "ti",
    "e",
    "i",
]

# unmapped = ['igv₂', 'liv₂', 'az', 'liv₁', 'eš', 'hašhur', 'nar', 'pab', 'eme', 'sig₅', 'gim', 'ar', 'kar', 'mašhalf', 'urudu', 'ah', 'ul', 'mun', 'dir', 'har', 'ug', 'kugv₂', 'ag', 'engur', 'gag', 'ezen₄', 'erim', 'munus', 'kugv₁', 'eš₅', 'nig₂', 'dah', 'ugu', 'ištar', 'kam', 'u₃', 'nin', 'gu₄', 'azug', 'man', 'zi₂', 'am', 'ia', 'šul', 'dur', 'siskur']


def map_cooh_signs():
    ebl = build_ebl_dict()
    unmapped = []
    mapped = []
    for x in parsed:
        asd = ebl.get(x.upper())
        if asd is None:
            unmapped.append(x)
        else:
            mapped.append(x)

    print("Unmapped: ", unmapped)
    print("Lenght Unmapped: ", len(unmapped))

    print("Mapped: ", mapped)
    print("Lenght Mapped: ", len(mapped))


if __name__ == "__main__":
    ebl = build_ebl_dict()
    bundled_path = Path("../../../data/raw-data/Cuneiform Dataset JOOCH bundled")
    destination = Path("../../../data/raw-data/Cuneiform Dataset JOOCH processed")
    jooch = {x: y for x, y in zip(cooh, parsed)}
    for file in bundled_path.iterdir():
        sign = file.stem.split("_")[0]
        abz = ebl.get(jooch[sign].upper())
        if abz is not None:
            shutil.copy(file, destination / f"{abz}_jooch_{file.stem}.png")


def bundle_cooh(source, destination):
    for dir1 in source.iterdir():
        for dir2 in dir1.iterdir():
            for dir3 in dir2.iterdir():
                for file in dir3.iterdir():
                    shutil.copy(file, destination)


def sign_set_from_bundled_jooch(path):
    signs = set()
    for file in path.iterdir():
        signs.add(file.stem.split("_")[0])
    return signs
